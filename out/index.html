<!DOCTYPE html><!--_g_zmhNjCGUXT8G_VgTCE--><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/yc.jpg"/><link rel="preload" as="image" href="/soical_logo/xiaohongshu.jpg"/><link rel="preload" as="image" href="https://raw.githubusercontent.com/ImYangC7/Repo-recorder/main/generated/overview.svg"/><link rel="stylesheet" href="/_next/static/css/5d0980c5cfdc386a.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-b894f21b5a870c85.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-d92e69f3ed28ec44.js" async=""></script><script src="/_next/static/chunks/main-app-dfcf1868335d7dde.js" async=""></script><script src="/_next/static/chunks/247-27b93a0bc11c40ab.js" async=""></script><script src="/_next/static/chunks/619-3ba632d834111881.js" async=""></script><script src="/_next/static/chunks/918-930ec979fb2e89b3.js" async=""></script><script src="/_next/static/chunks/app/layout-c0a73a7deaa786bc.js" async=""></script><script src="/_next/static/chunks/557-6332093812f5a0a4.js" async=""></script><script src="/_next/static/chunks/681-bd7c3298fd366f1d.js" async=""></script><script src="/_next/static/chunks/app/page-a3912e7d8ff54220.js" async=""></script><link rel="icon" href="/favicon.png" type="image/svg+xml"/><link rel="dns-prefetch" href="https://google-fonts.jialeliu.com"/><link rel="preconnect" href="https://google-fonts.jialeliu.com" crossorigin=""/><link rel="preload" as="style" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/><title>Cheng Yang (Êù®Êâø)</title><meta name="description" content="Undergraduate student at Hangzhou Dianzi University."/><meta name="author" content="Cheng Yang"/><meta name="keywords" content="Cheng Yang,PhD,Research,Hangzhou Dianzi University"/><meta name="creator" content="Cheng Yang"/><meta name="publisher" content="Cheng Yang"/><meta property="og:title" content="Cheng Yang (Êù®Êâø)"/><meta property="og:description" content="Undergraduate student at Hangzhou Dianzi University."/><meta property="og:site_name" content="Cheng Yang&#x27;s Academic Website"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Cheng Yang (Êù®Êâø)"/><meta name="twitter:description" content="Undergraduate student at Hangzhou Dianzi University."/><link rel="icon" href="/favicon.png"/><link rel="stylesheet" id="gfonts-css" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap" media="print"/><script>
              (function(){
                var l = document.getElementById('gfonts-css');
                if (!l) return;
                if (l.media !== 'all') {
                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });
                }
              })();
            </script><noscript><link rel="stylesheet" href="https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&amp;family=Crimson+Text:ital,wght@0,400;0,600;1,400&amp;display=swap"/></noscript><script>
              try {
                const theme = localStorage.getItem('theme-storage');
                const parsed = theme ? JSON.parse(theme) : null;
                const setting = parsed?.state?.theme || 'system';
                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));
                var root = document.documentElement;
                root.classList.add(effective);
                root.setAttribute('data-theme', effective);
              } catch (e) {
                var root = document.documentElement;
                root.classList.add('light');
                root.setAttribute('data-theme', 'light');
              }
            </script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-sans antialiased"><div hidden=""><!--$--><!--/$--></div><div style="visibility:hidden"><nav class="fixed top-0 left-0 right-0 z-50" data-headlessui-state=""><div class="transition-all duration-300 ease-out bg-transparent" style="transform:translateY(-100px)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16 lg:h-20"><div class="flex-shrink-0" tabindex="0"><a class="text-xl lg:text-2xl font-serif font-semibold text-primary hover:text-accent transition-colors duration-200" href="/">ImYangC7</a></div><div class="hidden lg:block"><div class="ml-10 flex items-center space-x-8"><div class="flex items-baseline space-x-8"><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-primary" href="/"><span class="relative z-10">About</span><div class="absolute inset-0 bg-accent/10 rounded-lg"></div></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/publications/"><span class="relative z-10">Publications</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/services/"><span class="relative z-10">Services</span></a><a class="relative px-3 py-2 text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm text-neutral-600 hover:text-primary" href="/cv/"><span class="relative z-10">CV</span></a></div><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div></div></div><div class="lg:hidden flex items-center space-x-2"><div class="flex items-center justify-center w-10 h-10 rounded-lg border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] bg-background dark:bg-neutral-800"><div class="w-4 h-4 rounded-full bg-neutral-300 animate-pulse"></div></div><button class="inline-flex items-center justify-center p-2 rounded-md text-neutral-600 hover:text-primary hover:bg-neutral-100 dark:hover:bg-neutral-800 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-accent transition-colors duration-200" id="headlessui-disclosure-button-_R_5pdb_" type="button" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open main menu</span><div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="block h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></div></button></div></div></div></div></nav><main class="min-h-screen pt-16 lg:pt-20"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen"><div class="grid grid-cols-1 lg:grid-cols-3 gap-12"><div class="lg:col-span-1"><div class="sticky top-8" style="opacity:0;transform:translateY(20px)"><div class="w-64 h-64 mx-auto mb-6 rounded-2xl overflow-hidden shadow-lg hover:shadow-xl transition-all duration-200 hover:scale-105"><img alt="Cheng Yang" width="256" height="256" decoding="async" data-nimg="1" class="w-full h-full object-cover object-[32%_center]" style="color:transparent" src="/yc.jpg"/></div><div class="text-center mb-6"><h1 class="text-3xl font-serif font-bold text-primary mb-2">Cheng Yang</h1><p class="text-lg text-accent font-medium mb-1">Undergraduate Student</p><p class="text-neutral-600 mb-2">Hangzhou Dianzi University</p></div><div class="flex flex-wrap justify-center gap-1 sm:gap-2 mb-6 relative px-2"><div class="relative"><button class="p-1.5 transition-colors duration-200 text-neutral-600 dark:text-neutral-400 hover:text-accent" aria-label="Email"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-7 w-7"><path stroke-linecap="round" stroke-linejoin="round" d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75"></path></svg></button></div><a href="https://scholar.google.com/citations?user=y7xaiIgAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="p-1.5 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="Google Scholar"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-7 w-7"><path stroke-linecap="round" stroke-linejoin="round" d="M4.26 10.147a60.438 60.438 0 0 0-.491 6.347A48.62 48.62 0 0 1 12 20.904a48.62 48.62 0 0 1 8.232-4.41 60.46 60.46 0 0 0-.491-6.347m-15.482 0a50.636 50.636 0 0 0-2.658-.813A59.906 59.906 0 0 1 12 3.493a59.903 59.903 0 0 1 10.399 5.84c-.896.248-1.783.52-2.658.814m-15.482 0A50.717 50.717 0 0 1 12 13.489a50.702 50.702 0 0 1 7.74-3.342M6.75 15a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm0 0v-3.675A55.378 55.378 0 0 1 12 8.443m-7.007 11.55A5.981 5.981 0 0 0 6.75 15.75v-1.5"></path></svg></a><a href="https://orcid.org/0009-0009-0947-656X" target="_blank" rel="noopener noreferrer" class="p-1.5 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="ORCID"><svg viewBox="0 0 24 24" fill="currentColor" class="h-7 w-7" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.372 0 0 5.372 0 12s5.372 12 12 12 12-5.372 12-12S18.628 0 12 0zM7.369 4.378c.525 0 .947.431.947.947s-.422.947-.947.947a.95.95 0 0 1-.947-.947c0-.525.422-.947.947-.947zm-.722 3.038h1.444v10.041H6.647V7.416zm3.562 0h3.9c3.712 0 5.344 2.653 5.344 5.025 0 2.578-2.016 5.025-5.325 5.025h-3.919V7.416zm1.444 1.303v7.444h2.297c3.272 0 4.022-2.484 4.022-3.722 0-2.016-1.284-3.722-4.097-3.722h-2.222z"></path></svg></a><a href="https://github.com/ImYangC7" target="_blank" rel="noopener noreferrer" class="p-1.5 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-7 w-7" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a href="https://www.xiaohongshu.com/user/profile/6554427a0000000008001276" target="_blank" rel="noopener noreferrer" class="p-1.5 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="Xiaohongshu"><img src="/soical_logo/xiaohongshu.jpg" alt="Xiaohongshu" class="h-7 w-7 rounded-sm object-cover"/></a><a href="https://raw.githubusercontent.com/ImYangC7/Repo-recorder/main/generated/wechat_yc.png" target="_blank" rel="noopener noreferrer" class="p-1.5 text-neutral-600 dark:text-neutral-400 hover:text-accent transition-colors duration-200" aria-label="WeChat"><svg viewBox="0 0 24 24" fill="currentColor" class="h-7 w-7" xmlns="http://www.w3.org/2000/svg"><path d="M8.691 2.188C3.891 2.188 0 5.476 0 9.53c0 2.212 1.17 4.203 3.002 5.55a.59.59 0 0 1 .213.665l-.39 1.48c-.019.07-.048.141-.048.213 0 .163.13.295.29.295a.326.326 0 0 0 .167-.054l1.903-1.114a.864.864 0 0 1 .717-.098 10.16 10.16 0 0 0 2.837.403c.276 0 .543-.027.811-.05-.857-2.578.157-4.972 1.932-6.446 1.703-1.415 3.882-1.98 5.853-1.838-.576-3.583-4.196-6.348-8.596-6.348zM5.785 5.991c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178A1.17 1.17 0 0 1 4.623 7.17c0-.651.52-1.18 1.162-1.18zm5.813 0c.642 0 1.162.529 1.162 1.18a1.17 1.17 0 0 1-1.162 1.178 1.17 1.17 0 0 1-1.162-1.178c0-.651.52-1.18 1.162-1.18zm5.34 2.867c-1.797-.052-3.746.512-5.28 1.786-1.72 1.428-2.687 3.72-1.78 6.22.942 2.453 3.666 4.229 6.884 4.229.826 0 1.622-.12 2.361-.336a.722.722 0 0 1 .598.082l1.584.926a.272.272 0 0 0 .14.047c.134 0 .24-.111.24-.247 0-.06-.023-.12-.038-.177l-.327-1.233a.582.582 0 0 1-.023-.156.49.49 0 0 1 .201-.398C23.024 18.48 24 16.82 24 14.98c0-3.21-2.931-5.837-6.656-6.088V8.89c-.135-.01-.269-.03-.407-.03zm-2.53 3.274c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.97-.982zm4.844 0c.535 0 .969.44.969.982a.976.976 0 0 1-.969.983.976.976 0 0 1-.969-.983c0-.542.434-.982.969-.982z"></path></svg></a></div><div class="bg-neutral-100 dark:bg-neutral-800 rounded-lg p-4 mb-6 hover:shadow-lg transition-all duration-200 hover:scale-[1.02]"><h3 class="font-serif font-semibold text-primary mb-3">Research Interests</h3><div class="space-y-2.5 text-base text-neutral-700 dark:text-neutral-400 font-serif"><div class="font-medium">LLM Reasoning</div><div class="font-medium">World Model</div><div class="font-medium">AI for Science</div></div></div><div class="mb-6"><a href="https://github.com/ImYangC7" target="_blank" rel="noopener noreferrer" class="block hover:opacity-80 transition-opacity duration-200"><img src="https://raw.githubusercontent.com/ImYangC7/Repo-recorder/main/generated/overview.svg" alt="GitHub Statistics" class="w-full rounded-lg"/></a></div><div class="flex justify-center"><div class="relative"><button class="flex items-center space-x-2 px-4 py-2 rounded-lg font-medium text-sm transition-all duration-200 bg-neutral-100 dark:bg-neutral-800 text-neutral-700 dark:text-neutral-500 hover:bg-red-50 dark:hover:bg-red-900/20 hover:text-red-600 dark:hover:text-red-400 cursor-pointer" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-4 w-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z"></path></svg><span>Like</span></button></div></div></div></div><div class="lg:col-span-2 space-y-8"><section id="about" class="scroll-mt-24 space-y-8"><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">About</h2><div class="text-neutral-700 dark:text-neutral-600 leading-relaxed"><p class="mb-4 last:mb-0">I‚Äôm currently a undergraduate student at <a href="https://en.itmo.ru/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">Hangzhou Dianzi University</a> and <a href="https://en.itmo.ru/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">ITMO University</a>, having enrolled in Fall 2023, and I‚Äôm pursuing a Bachelor‚Äôs degree in Computer Science and Technology.</p>
<p class="mb-4 last:mb-0">Currently, I‚Äôm working as a research intern at <a href="https://www.deepwisdom.ai/" node="[object Object]" target="_blank" rel="noopener noreferrer" class="text-accent font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm">MetaGPT</a>.</p>
<p class="mb-4 last:mb-0">My current research focuses on visual world models and AI scientists.</p></div></section><section style="opacity:0;transform:translateY(20px)"><div class="flex items-center justify-between mb-4"><h2 class="text-2xl font-serif font-bold text-primary">Selected Publications</h2><a class="text-accent hover:text-accent-dark text-sm font-medium transition-all duration-200 rounded hover:bg-accent/10 hover:shadow-sm" href="/#publications">View All ‚Üí</a></div><div class="space-y-4"><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">AAAI</span><img alt="LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/lungnodule.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2511.21042" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Hui Jin</span>, </span><span><span class=" ">Xinlei Yu</span>, </span><span><span class=" ">Zhipeng Wang</span>, </span><span><span class=" ">Yaoqun Liu</span>, </span><span><span class=" ">Fenglei Fan</span>, </span><span><span class=" ">Dajiang Lei</span>, </span><span><span class=" ">Gangyong Jia</span>, </span><span><span class=" ">Changmiao Wang</span>, </span><span><span class=" ">Ruiquan Ge</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">AAAI Conference on Artificial Intelligence (AAAI)<!-- -->, <!-- -->2026</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">arXiv</span><img alt="AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/autoenv.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2511.19304" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" ">Jiayi Zhang</span>, </span><span><span class=" ">Yiran Peng</span>, </span><span><span class=" ">Fanqi Kong</span>, </span><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Yifan Wu</span>, </span><span><span class=" ">Zhaoyang Yu</span>, </span><span><span class=" ">Jinyu Xiang</span>, </span><span><span class=" ">Jianhao Ruan</span>, </span><span><span class=" ">Jinlin Wang</span>, </span><span><span class=" ">Maojia Song</span>, </span><span><span class=" ">HongZhang Liu</span>, </span><span><span class=" ">Xiangru Tang</span>, </span><span><span class=" ">Bang Liu</span>, </span><span><span class=" ">Chenglin Wu</span>, </span><span><span class=" ">Yuyu Luo</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">arXiv preprint arXiv:2511.19304<!-- -->, <!-- -->2025</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">arXiv</span><img alt="Reasoning via Video: The First Evaluation of Video Models&#x27; Reasoning Abilities through Maze-Solving Tasks" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/vrbench.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2511.15065" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">Reasoning via Video: The First Evaluation of Video Models&#x27; Reasoning Abilities through Maze-Solving Tasks</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Haiyuan Wan</span>, </span><span><span class=" ">Yiran Peng</span>, </span><span><span class=" ">Xin Cheng</span>, </span><span><span class=" ">Zhaoyang Yu</span>, </span><span><span class=" ">Jiayi Zhang</span>, </span><span><span class=" ">Junchi Yu</span>, </span><span><span class=" ">Xinlei Yu</span>, </span><span><span class=" ">Xiawu Zheng</span>, </span><span><span class=" ">Dongzhan Zhou</span>, </span><span><span class=" ">Chenglin Wu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">arXiv preprint arXiv:2511.15065<!-- -->, <!-- -->2025</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">arXiv</span><img alt="From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/chemmas.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2509.23768" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Jiaxuan Lu</span>, </span><span><span class=" ">Haiyuan Wan</span>, </span><span><span class=" ">Junchi Yu</span>, </span><span><span class=" ">Feiwei Qin</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">arXiv preprint arXiv:2509.23768<!-- -->, <!-- -->2025</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">BIBM Oral</span><img alt="RTGMFF: Enhanced fmri-based brain disorder diagnosis via roi-driven text generation and multimodal feature fusion" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/rtgmff.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2509.03214" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">RTGMFF: Enhanced fmri-based brain disorder diagnosis via roi-driven text generation and multimodal feature fusion</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" ">Junhao Jia</span>, </span><span><span class=" ">Yifei Sun</span>, </span><span><span class=" ">Yunyou Liu</span>, </span><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Changmiao Wang</span>, </span><span><span class=" ">Feiwei Qin</span>, </span><span><span class=" ">Yong Peng</span>, </span><span><span class=" ">Wenwen Min</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">IEEE International Conference on Bioinformatics and Biomedicine (BIBM)<!-- -->, <!-- -->2025</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">arXiv</span><img alt="Visual Document Understanding and Reasoning: A Multi-Agent Collaboration Framework with Agent-Wise Adaptive Test-Time Scaling" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/mact.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://arxiv.org/abs/2508.03404" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">Visual Document Understanding and Reasoning: A Multi-Agent Collaboration Framework with Agent-Wise Adaptive Test-Time Scaling</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" ">Xinlei Yu</span>, </span><span><span class=" ">Chengming Xu</span>, </span><span><span class=" ">Zhangquan Chen</span>, </span><span><span class=" ">Yudong Zhang</span>, </span><span><span class=" ">Shilin Lu</span>, </span><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Jiangning Zhang</span>, </span><span><span class=" ">Shuicheng Yan</span>, </span><span><span class=" ">Xiaobin Hu</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">arXiv preprint arXiv:2508.03404<!-- -->, <!-- -->2025</p></div></div></div><div class="bg-neutral-50 dark:bg-neutral-800 p-4 rounded-lg shadow-sm border border-neutral-200 dark:border-[rgba(148,163,184,0.24)] hover:shadow-lg transition-all duration-200 hover:scale-[1.02]" style="opacity:0;transform:translateY(20px)"><div class="flex flex-col sm:flex-row gap-4"><div class="w-full sm:w-44 flex-shrink-0"><div class="relative p-1 rounded-lg bg-white dark:bg-neutral-700 shadow-md hover:shadow-xl transition-shadow duration-300 ring-1 ring-neutral-200 dark:ring-neutral-600"><span class="absolute top-0 left-0 z-10 px-1.5 py-0.5 text-[10px] font-bold text-white bg-blue-900 rounded-br-md shadow-md" style="font-family:Arial, sans-serif">MICCAI</span><img alt="Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification" loading="lazy" width="200" height="150" decoding="async" data-nimg="1" class="w-full h-auto rounded hover:scale-105 transition-transform duration-300" style="color:transparent" src="/papers/Lesions-aware.jpg"/></div></div><div class="flex-grow"><h3 class="font-semibold text-primary mb-2 leading-tight"><a href="https://link.springer.com/chapter/10.1007/978-3-032-04927-8_56" target="_blank" rel="noopener noreferrer" class="hover:text-accent transition-colors duration-200">Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification</a></h3><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-1"><span><span class=" ">Jianxun Yu</span>, </span><span><span class=" ">Ruiquan Ge</span>, </span><span><span class=" ">Zhipeng Wang</span>, </span><span><span class="font-semibold text-accent ">Cheng Yang</span>, </span><span><span class=" ">Chenyu Lin</span>, </span><span><span class=" ">Xianjun Fu</span>, </span><span><span class=" ">Jikui Liu</span>, </span><span><span class=" ">Ahmed Elazab</span>, </span><span><span class=" ">Changmiao Wang</span></span></p><p class="text-sm text-neutral-600 dark:text-neutral-500 mb-2">International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)<!-- -->, <!-- -->2025</p></div></div></div></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">News</h2><div class="space-y-3"><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-11</span><p class="text-sm text-neutral-700 dark:text-neutral-400">üöÄ <a href="https://github.com/YU-deep/Awesome-Latent-Space" target="_blank" rel="noopener noreferrer" class="text-accent hover:underline font-medium">Awesome-Latent-Space</a> is released!</p></div><div class="flex items-start space-x-3"><span class="text-xs text-neutral-500 mt-1 w-16 flex-shrink-0">2025-11</span><p class="text-sm text-neutral-700 dark:text-neutral-400">Our paper on AI for medical applications has been accepted to AAAI 2026!</p></div></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">Competitions</h2><div class="space-y-4"><div><h3 class="text-lg font-semibold text-neutral-800 dark:text-neutral-300 mb-2">International &amp; National Prizes</h3><div class="overflow-y-auto pr-2 space-y-2" style="max-height:220px"><ul class="list-disc list-outside ml-4 space-y-2"><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://jsjds.blcu.edu.cn" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">Chinese Collegiate Computing Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National First Prize</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://jsjds.blcu.edu.cn" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">Chinese Collegiate Computing Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National Third Prize</span><span class="text-neutral-500">, </span><span>Key Member</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="http://computergames.caai.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">University Computer Games championship</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National First Prize</span><span class="text-neutral-500">, </span><span>Key Member</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://cy.ncss.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China International College Students&#x27; Innovation Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National Gold Medal</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://cy.ncss.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China International College Students&#x27; Innovation Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National Bronze Medal</span><span class="text-neutral-500">, </span><span>Key Member</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://cy.ncss.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China International College Students&#x27; Innovation Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">International Bronze Medal</span><span class="text-neutral-500">, </span><span>Key Member</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://2025.tiaozhanbei.net/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">&quot;Challenge Cup&quot; National Undergraduate Extracurricular Academic Science and Technology Works Competition ‚Äî &quot;Unveiling the List&quot; Special Track</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National Second Prize</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="http://www.csbme.org/headline/1476.htm" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">National Collegiate Biomedical Engineering Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">National Second Prize</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li></ul></div><p class="text-xs text-neutral-400 mt-1">‚Üï Scrollable</p></div><div><h3 class="text-lg font-semibold text-neutral-800 dark:text-neutral-300 mb-2">Regional &amp; Provincial Prizes</h3><div class="overflow-y-auto pr-2 space-y-2" style="max-height:180px"><ul class="list-disc list-outside ml-4 space-y-2"><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://www.mcm.edu.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China Undergraduate Mathematical Contest in Modeling (CUMCM)</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">Provincial First Prize</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://cy.ncss.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China International College Students&#x27; Innovation Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">Provincial Gold Medal</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="http://www.fwwb.org.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China College Students&#x27; Service Outsourcing Innovation and Entrepreneurship Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">Regional Second Prize</span><span class="text-neutral-500">, </span><span>Project Leader</span><span class="text-neutral-500">)</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="text-neutral-500">2025<!-- -->: </span><a href="https://cy.ncss.cn/" target="_blank" rel="noopener noreferrer" class="text-neutral-700 dark:text-neutral-400 hover:underline">China International College Students&#x27; Innovation Competition</a><span class="text-neutral-500"> (</span><span class="font-medium text-yellow-600 dark:text-yellow-500">Provincial Silver Medal</span><span class="text-neutral-500">, </span><span>Key Member</span><span class="text-neutral-500">)</span></li></ul></div><p class="text-xs text-neutral-400 mt-1">‚Üï Scrollable</p></div></div></section><section style="opacity:0;transform:translateY(20px)"><h2 class="text-2xl font-serif font-bold text-primary mb-4">Awards</h2><ul class="list-disc list-outside ml-4 space-y-2"><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="italic text-neutral-500">2024-2025 Academic Year</span><span>, </span><span><span class="font-bold">University First-Class Scholarships</span></span><span><span> and </span><span class="font-bold">Zhejiang Provincial Government Scholarship</span></span><span> <!-- -->twice</span><span>.</span></li><li class="text-sm text-neutral-700 dark:text-neutral-400"><span class="italic text-neutral-500">2023-2024 Academic Year</span><span>, </span><span><span class="font-bold">University First-Class Scholarships</span></span><span><span> and </span><span class="font-bold">Zhejiang Provincial Government Scholarship</span></span><span> <!-- -->twice</span><span>.</span></li></ul></section></section></div></div></div><!--$--><!--/$--></main><footer class="border-t border-neutral-200/50 bg-neutral-50/50 dark:bg-neutral-900/50 dark:border-neutral-700/50"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-6"><div class="flex flex-col sm:flex-row justify-center items-center gap-2"><p class="text-xs text-neutral-500">Last updated: <!-- -->December 5, 2025</p></div></div></footer></div><script src="/_next/static/chunks/webpack-b894f21b5a870c85.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7558,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"918\",\"static/chunks/918-930ec979fb2e89b3.js\",\"177\",\"static/chunks/app/layout-c0a73a7deaa786bc.js\"],\"ThemeProvider\"]\n3:I[9994,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"918\",\"static/chunks/918-930ec979fb2e89b3.js\",\"177\",\"static/chunks/app/layout-c0a73a7deaa786bc.js\"],\"default\"]\n4:I[9766,[],\"\"]\n5:I[8924,[],\"\"]\nb:I[7150,[],\"\"]\n:HL[\"/_next/static/css/5d0980c5cfdc386a.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"_g-zmhNjCGUXT8G-VgTCE\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5d0980c5cfdc386a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.png\",\"type\":\"image/svg+xml\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://google-fonts.jialeliu.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://google-fonts.jialeliu.com\",\"crossOrigin\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preload\",\"as\":\"style\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}],[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"id\":\"gfonts-css\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\",\"media\":\"print\",\"suppressHydrationWarning\":true}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              (function(){\\n                var l = document.getElementById('gfonts-css');\\n                if (!l) return;\\n                if (l.media !== 'all') {\\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\\n                }\\n              })();\\n            \"}}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"link\",null,{\"rel\":\"stylesheet\",\"href\":\"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700\u0026family=Crimson+Text:ital,wght@0,400;0,600;1,400\u0026display=swap\"}]}],[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n              try {\\n                const theme = localStorage.getItem('theme-storage');\\n                const parsed = theme ? JSON.parse(theme) : null;\\n                const setting = parsed?.state?.theme || 'system';\\n                const prefersDark = typeof window !== 'undefined' \u0026\u0026 window.matchMedia \u0026\u0026 window.matchMedia('(prefers-color-scheme: dark)').matches;\\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\\n                var root = document.documentElement;\\n                root.classList.add(effective);\\n                root.setAttribute('data-theme', effective);\\n              } catch (e) {\\n                var root = document.documentElement;\\n                root.classList.add('light');\\n                root.setAttribute('data-theme', 'light');\\n              }\\n            \"}}]]}],[\"$\",\"body\",null,{\"className\":\"font-sans antialiased\",\"children\":[\"$\",\"$L2\",null,{\"children\":[[\"$\",\"$L3\",null,{\"items\":[{\"title\":\"About\",\"type\":\"page\",\"target\":\"about\",\"href\":\"/\"},{\"title\":\"Publications\",\"type\":\"page\",\"target\":\"publications\",\"href\":\"/publications\"},{\"title\":\"Services\",\"type\":\"page\",\"target\":\"services\",\"href\":\"/services\"},{\"title\":\"CV\",\"type\":\"page\",\"target\":\"cv\",\"href\":\"/cv\"}],\"siteTitle\":\"ImYangC7\",\"enableOnePageMode\":false}],[\"$\",\"main\",null,{\"className\":\"min-h-screen pt-16 lg:pt-20\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],\"$L6\",\"$L7\"]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],\"$L8\"]}]}]]}]]}],{\"children\":[\"__PAGE__\",\"$L9\",{},null,false]},null,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[7923,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"918\",\"static/chunks/918-930ec979fb2e89b3.js\",\"177\",\"static/chunks/app/layout-c0a73a7deaa786bc.js\"],\"default\"]\nd:I[9756,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\ne:I[470,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\nf:I[2597,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\n14:I[4431,[],\"ViewportBoundary\"]\n16:I[4431,[],\"MetadataBoundary\"]\n17:\"$Sreact.suspense\"\n6:[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}]\n7:[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]\n8:[\"$\",\"$Lc\",null,{\"lastUpdated\":\"December 5, 2025\"}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 lg:grid-cols-3 gap-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"lg:col-span-1\",\"children\":[\"$\",\"$Ld\",null,{\"author\":{\"name\":\"Cheng Yang\",\"title\":\"Undergraduate Student\",\"institution\":\"Hangzhou Dianzi University\",\"avatar\":\"/yc.jpg\"},\"social\":{\"email\":\"23320214@hdu.edu.cn\",\"google_scholar\":\"https://scholar.google.com/citations?user=y7xaiIgAAAAJ\u0026hl=en\",\"orcid\":\"https://orcid.org/0009-0009-0947-656X\",\"github\":\"https://github.com/ImYangC7\",\"xiaohongshu\":\"https://www.xiaohongshu.com/user/profile/6554427a0000000008001276\",\"wechat\":\"https://raw.githubusercontent.com/ImYangC7/Repo-recorder/main/generated/wechat_yc.png\"},\"features\":{\"enable_likes\":true,\"enable_one_page_mode\":false},\"researchInterests\":[\"LLM Reasoning\",\"World Model\",\"AI for Science\"]}]}],[\"$\",\"div\",null,{\"className\":\"lg:col-span-2 space-y-8\",\"children\":[[\"$\",\"section\",\"about\",{\"id\":\"about\",\"className\":\"scroll-mt-24 space-y-8\",\"children\":[[[\"$\",\"$Le\",\"about\",{\"content\":\"I‚Äôm currently a undergraduate student at [Hangzhou Dianzi University](https://en.itmo.ru/) and [ITMO University](https://en.itmo.ru/), having enrolled in Fall 2023, and I‚Äôm pursuing a Bachelor‚Äôs degree in Computer Science and Technology. \\r\\n\\r\\nCurrently, I‚Äôm working as a research intern at [MetaGPT](https://www.deepwisdom.ai/).\\r\\n\\r\\nMy current research focuses on visual world models and AI scientists.\",\"title\":\"About\"}],[\"$\",\"$Lf\",\"featured_publications\",{\"publications\":[{\"id\":\"yang2025lungnoduleagent\",\"title\":\"LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules\",\"authors\":[{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Hui Jin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinlei Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhipeng Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yaoqun Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Fenglei Fan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Dajiang Lei\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Gangyong Jia\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changmiao Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruiquan Ge\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2026,\"month\":\"1\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:0:tags\",\"researchArea\":\"reliability-engineering\",\"journal\":\"AAAI Conference on Artificial Intelligence (AAAI)\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2511.21042\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"lungnodule.jpg\",\"venue\":\"AAAI\",\"bibtex\":\"@article{yang2025lungnoduleagent,\\n  title = {LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules},\\n  author = {Yang, Cheng and Jin, Hui and Yu, Xinlei and Wang, Zhipeng and Liu, Yaoqun and Fan, Fenglei and Lei, Dajiang and Jia, Gangyong and Wang, Changmiao and Ge, Ruiquan},\\n  journal = {AAAI Conference on Artificial Intelligence (AAAI)},\\n  year = {2026},\\n  url = {https://arxiv.org/abs/2511.21042}\\n}\"},{\"id\":\"zhang2025autoenv\",\"title\":\"AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning\",\"authors\":[{\"name\":\"Jiayi Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yiran Peng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Fanqi Kong\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yifan Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhaoyang Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jinyu Xiang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jianhao Ruan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jinlin Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Maojia Song\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"HongZhang Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiangru Tang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Bang Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenglin Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yuyu Luo\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"11\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:1:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2511.19304\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2511.19304\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"autoenv.jpg\",\"venue\":\"arXiv\",\"bibtex\":\"@article{zhang2025autoenv,\\n  title = {AutoEnv: Automated Environments for Measuring Cross-Environment Agent Learning},\\n  author = {Jiayi Zhang and Yiran Peng and Fanqi Kong and Cheng Yang and Yifan Wu and Zhaoyang Yu and Jinyu Xiang and Jianhao Ruan and Jinlin Wang and Maojia Song and HongZhang Liu and Xiangru Tang and Bang Liu and Chenglin Wu and Yuyu Luo},\\n  journal = {arXiv preprint arXiv:2511.19304},\\n  year = {2025},\\n  url = {https://arxiv.org/abs/2511.19304}\\n}\"},{\"id\":\"yang2025vrbench\",\"title\":\"Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks\",\"authors\":[{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haiyuan Wan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yiran Peng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xin Cheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhaoyang Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiayi Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Junchi Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xinlei Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiawu Zheng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Dongzhan Zhou\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenglin Wu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"11\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:2:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2511.15065\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2511.15065\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"vrbench.jpg\",\"venue\":\"arXiv\",\"bibtex\":\"@article{yang2025vrbench,\\n  title = {Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks},\\n  author = {Cheng Yang and Haiyuan Wan and Yiran Peng and Xin Cheng and Zhaoyang Yu and Jiayi Zhang and Junchi Yu and Xinlei Yu and Xiawu Zheng and Dongzhan Zhou and Chenglin Wu},\\n  journal = {arXiv preprint arXiv:2511.15065},\\n  year = {2025},\\n  url = {https://arxiv.org/abs/2511.15065}\\n}\"},{\"id\":\"yang2025multi\",\"title\":\"From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning\",\"authors\":[{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiaxuan Lu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Haiyuan Wan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Junchi Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Feiwei Qin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"9\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:3:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2509.23768\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2509.23768\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"chemmas.jpg\",\"venue\":\"arXiv\",\"bibtex\":\"@article{yang2025multi,\\n  title = {From What to Why: A Multi-Agent System for Evidence-based Chemical Reaction Condition Reasoning},\\n  author = {Yang, Cheng and Lu, Jiaxuan and Wan, Haiyuan and Yu, Junchi and Qin, Feiwei},\\n  journal = {arXiv preprint arXiv:2509.23768},\\n  year = {2025},\\n  url = {https://arxiv.org/abs/2509.23768}\\n}\"},{\"id\":\"jia2025rtgmff\",\"title\":\"RTGMFF: Enhanced fmri-based brain disorder diagnosis via roi-driven text generation and multimodal feature fusion\",\"authors\":[{\"name\":\"Junhao Jia\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yifei Sun\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yunyou Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changmiao Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Feiwei Qin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yong Peng\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Wenwen Min\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"9\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:4:tags\",\"researchArea\":\"reliability-engineering\",\"journal\":\"IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2509.03214\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"rtgmff.jpg\",\"venue\":\"BIBM Oral\",\"bibtex\":\"@article{jia2025rtgmff,\\n  title = {RTGMFF: Enhanced fmri-based brain disorder diagnosis via roi-driven text generation and multimodal feature fusion},\\n  author = {Jia, Junhao and Sun, Yifei and Liu, Yunyou and Yang, Cheng and Wang, Changmiao and Qin, Feiwei and Peng, Yong and Min, Wenwen},\\n  journal = {IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},\\n  year = {2025},\\n  url = {https://arxiv.org/abs/2509.03214}\\n}\"},{\"id\":\"yu2025visualdocumentunderstandingreasoning\",\"title\":\"Visual Document Understanding and Reasoning: A Multi-Agent Collaboration Framework with Agent-Wise Adaptive Test-Time Scaling\",\"authors\":[{\"name\":\"Xinlei Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chengming Xu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhangquan Chen\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Yudong Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shilin Lu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jiangning Zhang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Shuicheng Yan\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xiaobin Hu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"8\",\"type\":\"preprint\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:5:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"arXiv preprint arXiv:2508.03404\",\"conference\":\"\",\"url\":\"https://arxiv.org/abs/2508.03404\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"mact.jpg\",\"venue\":\"arXiv\",\"bibtex\":\"@misc{yu2025visualdocumentunderstandingreasoning,\\n  title = {Visual Document Understanding and Reasoning: A Multi-Agent Collaboration Framework with Agent-Wise Adaptive Test-Time Scaling},\\n  author = {Xinlei Yu and Chengming Xu and Zhangquan Chen and Yudong Zhang and Shilin Lu and Cheng Yang and Jiangning Zhang and Shuicheng Yan and Xiaobin Hu},\\n  journal = {arXiv preprint arXiv:2508.03404},\\n  year = {2025},\\n  url = {https://arxiv.org/abs/2508.03404}\\n}\"},{\"id\":\"yu2025small\",\"title\":\"Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification\",\"authors\":[{\"name\":\"Jianxun Yu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ruiquan Ge\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Zhipeng Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Cheng Yang\",\"isHighlighted\":true,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Chenyu Lin\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Xianjun Fu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Jikui Liu\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Ahmed Elazab\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false},{\"name\":\"Changmiao Wang\",\"isHighlighted\":false,\"isCorresponding\":false,\"isCoAuthor\":false}],\"year\":2025,\"month\":\"4\",\"type\":\"journal\",\"status\":\"published\",\"tags\":[],\"keywords\":\"$9:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:6:tags\",\"researchArea\":\"machine-learning\",\"journal\":\"\",\"conference\":\"International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)\",\"pages\":\"589--598\",\"url\":\"https://link.springer.com/chapter/10.1007/978-3-032-04927-8_56\",\"abstract\":\"\",\"description\":\"\",\"selected\":true,\"preview\":\"Lesions-aware.jpg\",\"venue\":\"MICCAI\",\"bibtex\":\"@article{yu2025small,\\n  title = {Small Lesions-aware Bidirectional Multimodal Multiscale Fusion Network for Lung Disease Classification},\\n  author = {Yu, Jianxun and Ge, Ruiquan and Wang, Zhipeng and Yang, Cheng and Lin, Chenyu and Fu, Xianjun and Liu, Jikui and Elazab, Ahmed and Wang, Changmiao},\\n  booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)},\\n  pages = {589--598},\\n  year = {2025},\\n  organization = {Springer},\\n  url = {https://link.springer.com/chapter/10.1007/978-3-032-04927-8_56}\\n}\"}],\"title\":\"Selected Publications\",\"enableOnePageMode\":true}],\"$L10\",\"$L11\",\"$L12\"],false,false,false]}]]}]]}]}],null,\"$L13\"]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L14\",null,{\"children\":\"$L15\"}],null],[\"$\",\"$L16\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$17\",null,{\"fallback\":null,\"children\":\"$L18\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"19:I[5078,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\n1a:I[9603,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\n1b:I[1933,[\"247\",\"static/chunks/247-27b93a0bc11c40ab.js\",\"557\",\"static/chunks/557-6332093812f5a0a4.js\",\"619\",\"static/chunks/619-3ba632d834111881.js\",\"681\",\"static/chunks/681-bd7c3298fd366f1d.js\",\"974\",\"static/chunks/app/page-a3912e7d8ff54220.js\"],\"default\"]\n1c:I[4431,[],\"OutletBoundary\"]\n1e:I[5278,[],\"AsyncMetadataOutlet\"]\n10:[\"$\",\"$L19\",\"news\",{\"items\":[{\"date\":\"2025-11\",\"content\":\"üöÄ [Awesome-Latent-Space](https://github.com/YU-deep/Awesome-Latent-Space) is released!\"},{\"date\":\"2025-11\",\"content\":\"Our paper on AI for medical applications has been accepted to AAAI 2026!\"}],\"title\":\"News\"}]\n"])</script><script>self.__next_f.push([1,"11:[\"$\",\"$L1a\",\"competitions\",{\"national\":[{\"date\":\"2025\",\"name\":\"Chinese Collegiate Computing Competition\",\"url\":\"https://jsjds.blcu.edu.cn\",\"prize\":\"National First Prize\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"Chinese Collegiate Computing Competition\",\"url\":\"https://jsjds.blcu.edu.cn\",\"prize\":\"National Third Prize\",\"role\":\"Key Member\"},{\"date\":\"2025\",\"name\":\"University Computer Games championship\",\"url\":\"http://computergames.caai.cn/\",\"prize\":\"National First Prize\",\"role\":\"Key Member\"},{\"date\":\"2025\",\"name\":\"China International College Students' Innovation Competition\",\"url\":\"https://cy.ncss.cn/\",\"prize\":\"National Gold Medal\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"China International College Students' Innovation Competition\",\"url\":\"https://cy.ncss.cn/\",\"prize\":\"National Bronze Medal\",\"role\":\"Key Member\"},{\"date\":\"2025\",\"name\":\"China International College Students' Innovation Competition\",\"url\":\"https://cy.ncss.cn/\",\"prize\":\"International Bronze Medal\",\"role\":\"Key Member\"},{\"date\":\"2025\",\"name\":\"\\\"Challenge Cup\\\" National Undergraduate Extracurricular Academic Science and Technology Works Competition ‚Äî \\\"Unveiling the List\\\" Special Track\",\"url\":\"https://2025.tiaozhanbei.net/\",\"prize\":\"National Second Prize\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"National Collegiate Biomedical Engineering Competition\",\"url\":\"http://www.csbme.org/headline/1476.htm\",\"prize\":\"National Second Prize\",\"role\":\"Project Leader\"}],\"provincial\":[{\"date\":\"2025\",\"name\":\"China Undergraduate Mathematical Contest in Modeling (CUMCM)\",\"url\":\"https://www.mcm.edu.cn/\",\"prize\":\"Provincial First Prize\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"China International College Students' Innovation Competition\",\"url\":\"https://cy.ncss.cn/\",\"prize\":\"Provincial Gold Medal\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"China College Students' Service Outsourcing Innovation and Entrepreneurship Competition\",\"url\":\"http://www.fwwb.org.cn/\",\"prize\":\"Regional Second Prize\",\"role\":\"Project Leader\"},{\"date\":\"2025\",\"name\":\"China International College Students' Innovation Competition\",\"url\":\"https://cy.ncss.cn/\",\"prize\":\"Provincial Silver Medal\",\"role\":\"Key Member\"}],\"title\":\"Competitions\"}]\n"])</script><script>self.__next_f.push([1,"12:[\"$\",\"$L1b\",\"awards\",{\"items\":[{\"date\":\"2024-2025 Academic Year\",\"awards\":[\"University First-Class Scholarships\",\"Zhejiang Provincial Government Scholarship\"],\"suffix\":\"twice\"},{\"date\":\"2023-2024 Academic Year\",\"awards\":[\"University First-Class Scholarships\",\"Zhejiang Provincial Government Scholarship\"],\"suffix\":\"twice\"}],\"title\":\"Awards\"}]\n13:[\"$\",\"$L1c\",null,{\"children\":[\"$L1d\",[\"$\",\"$L1e\",null,{\"promise\":\"$@1f\"}]]}]\n"])</script><script>self.__next_f.push([1,"15:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1d:null\n"])</script><script>self.__next_f.push([1,"20:I[622,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"1f:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Cheng Yang (Êù®Êâø)\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Undergraduate student at Hangzhou Dianzi University.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Cheng Yang\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Cheng Yang,PhD,Research,Hangzhou Dianzi University\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Cheng Yang\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Cheng Yang\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"Cheng Yang (Êù®Êâø)\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Undergraduate student at Hangzhou Dianzi University.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"Cheng Yang's Academic Website\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Cheng Yang (Êù®Êâø)\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Undergraduate student at Hangzhou Dianzi University.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/favicon.png\"}],[\"$\",\"$L20\",\"15\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"18:\"$1f:metadata\"\n"])</script></body></html>